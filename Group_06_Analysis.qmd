---
title: "Group_06"
author: "Analysis of IMDB data set"
number-sections: true
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf:
    geometry: "left=2cm, right=2cm, top=2cm, bottom=2cm"
editor_options: 
  chunk_output_type: console
execute:
  echo: false
  eval: true
  warning: false
  message: false
---

```{r}
#| label: libraries
library(ggplot2)
library(dplyr)
library(tidyverse)
library(gt)
library(patchwork)
library(gridExtra)
library(moderndive)
library(MASS)
library(knitr)
library(GGally)
library(skimr)
library(ggpubr)
```

# Introduction {#sec-Intro}

The study aims to investigate the relationship between various film attributes and IMDB ratings, drawing data from the IMDB film database allocated. The data set comprises of the factors such as film ID, release year, duration, budget, votes, genre, and IMDB rating. The research question focuses on examining the factors that impact IMDB ratings, particularly whether specific film properties contribute to ratings greater than seven. A Generalized Linear Model (GLM) analysis is conducted to derive the relationships between these properties and IMDB ratings.

```{r}
# Import the data sets
imdb_data <- read.csv("dataset06.csv")

```

# Data Wrangling Methods {#sec-DW}

Before we begin the analysis of our data, let's transform the data using various tools. The process below describes the detailed data wrangling techniques that are used to get the desired data set. After having a glimpse of the data set, the 'genre' column is converted to a type factor type.

```{r}
imdb_data$genre <- as.factor(imdb_data$genre) # genre column converted from character type to factor type
```

A check for missing values is conducted and it is found that 103 observations are missing from the column 'length'. Missing values are imputed with the median since median is a robust measure, less impacted by outliers as much as mean. The function *median( )* reveals the median to be 90 minutes. However, it is observed in @tbl-median-length that the median lengths vary across the different genres. With this information, the missing lengths of films are replaced by median length of the respective genre.

```{r}
#| label: tbl-median-length
#| tbl-cap: Median length by genre.
# Check for missing values
missing_values <- colSums(is.na(imdb_data)) # 103 values are missing from the column length

median_length <- median(imdb_data$length, na.rm = TRUE) # median is 90 minutes

median_length_by_genre <- imdb_data %>%
  group_by(genre) %>% 
  summarize(median_length = median(length, na.rm = TRUE))

kable(median_length_by_genre, caption = "Median Length by Genre")

for (i in 1:nrow(median_length_by_genre)) {
  genre <- median_length_by_genre$genre[i]
  median_length <- median_length_by_genre$median_length[i]
  imdb_data$length[imdb_data$genre == genre & is.na(imdb_data$length)] <- median_length
}
```

As per the research question, a new column 'high_rating' containing binary variables coressponding to 'rating' values is created. This column takes a value of 1 for IMDB ratings greater than or equal to seven and 0 for IMDB ratings less than seven. Additionally, another categorical variable 'rate' conveying the same is also added.

```{r}
#new binary column#
imdb_data$high_rating <- ifelse(imdb_data$rating >= 7, 1, 0)
imdb_data$high_rating <- factor(imdb_data$high_rating, levels = c(0, 1))

#Add a categorcial variable as a column
imdb_data$rate<- ifelse(imdb_data$rating >= 7, "Rating greater than 7", "Rating less than 7")
imdb_data$rate <- factor(imdb_data$rate)
```

# Exploratory Data Analysis {#sec-EDA}

## view the data

Check on the size of a data set

```{r}
# check on the size of a data set
dim(imdb_data)
```

Sample size is 1937. And it have 9 variables,7 of which are in the original data.

Let's have a look at the first five rows of the data frame.

```{r}
#| label: tbl-glimpse-dataset
#| tbl-cap: Glimpse of the first five rows in the IMDB data set.
imdb_data |>
  slice_head(n=5) |>
  gt()
```

The variables in @tbl-glimpse-dataset

-   **film.id** : The unique identifier for the film

-   **year** : Year of release of the film in cinemas

-   **length** : Duration (in minutes)

-   **budget** : Budget for the films production (in \$1000000s)

-   **votes** : Number of positive votes received by viewers

-   **genre** : Genre of the film

-   **rating** : IMDB rating from 0 to10

-   **high_rating** : 1 for IMDB ratings greater than or equal to seven and 0 for IMDB ratings less than 7

-   **rate** : 'Rating greater than 7' got high_rating = 1 and 'Rating less than 7' for high_rating = 0

## Summary Statistics {#sec-sum}

Since variables year, length,budget,votes,rating are continuous, we need get their summary contains mean,median,standard deviation,minimum maximum.

```{r}
#| label: tbl-summary-statistics
#| tbl-cap: Summary statistics on the IMDB data by variables.
summary_year <- imdb_data %>%
  summarise('Variables'="year",
            'Mean' = mean(year),
            'Median' = median(year),
            'St.Dev' = sd(year),
            'Min' = min(year),
            'Max' = max(year),
            'IQR' = quantile(year,0.75)-quantile(year,0.25),
            'Sample_size' = n())
summary_length <- imdb_data %>%
  summarise('Variables'="length",
            'Mean' = mean(length),
            'Median' = median(length),
            'St.Dev' = sd(length),
            'Min' = min(length),
            'Max' = max(length),
            'IQR' = quantile(length,0.75)-quantile(length,0.25),
            'Sample_size' = n())
summary_budget <- imdb_data %>%
  summarise('Variables'="budget",
            'Mean' = mean(budget),
            'Median' = median(budget),
            'St.Dev' = sd(budget),
            'Min' = min(budget),
            'Max' = max(budget),
            'IQR' = quantile(budget,0.75)-quantile(budget,0.25),
            'Sample_size' = n())
summary_votes <- imdb_data %>%
  summarise('Variables'="votes",
            'Mean' = mean(votes),
            'Median' = median(votes),
            'St.Dev' = sd(votes),
            'Min' = min(votes),
            'Max' = max(votes),
            'IQR' = quantile(votes,0.75)-quantile(votes,0.25),
            'Sample_size' = n())
summary_rating <- imdb_data %>%
  summarise('Variables'="rating",
            'Mean' = mean(rating),
            'Median' = median(rating),
            'St.Dev' = sd(rating),
            'Min' = min(rating),
            'Max' = max(rating),
            'IQR' = quantile(rating,0.75)-quantile(rating,0.25),
            'Sample_size' = n())

combined_summary <- bind_rows(summary_year, summary_length, summary_budget, summary_votes, summary_rating)
combined_summary |>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Variables=html("Variables"),
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  ) 
```

The @tbl-summary-statistics shows that the summary for the columns year, length, budget and votes.

• The number of films in sample is 1937.

• For the variable year, the years of the films ranged from 1896 to 2005.

• For the variable length, the films runs from 1 minute to 316 minutes.The average length of a movie is 83.22 minutes.

• For variable budget, the budget of films is from 3.2 (\$1000000s) to 21.2 (\$1000000s).The median budget of a movie is 12(\$1000000s).

• For variable votes, the votes of films is from 5 to 103,854.The range of variation is very large, and the IQR is relatively large. The data is not stable.

## Correlation {#sec-cor}

Check correlations (as scatterplots), distribution and print correlation coefficient.

```{r}
#| label: fig-scatterplot-matrix
#| fig-cap: Scatterplot matrix between rating and explanatory variables.
#| fig-align: center
#| fig-width: 7
#| fig-height: 6
#| message: false
scatterplot_matrix <- ggpairs(imdb_data[, c("rating","year", "budget",  "length", "votes")], 
                              title="Scatterplot matrix")
scatterplot_matrix
```

@fig-scatterplot-matrix shows rating and budget show a significant linear positive correlation. And rating is significant linear negative correlation with length. Between rating and year,votes have weak correlation.

## Visualization {#sec-viz}

### Histograms for continuous variable(rating,year,budget,length,votes)

Histograms to understand the data structures of different variables

```{r}
#| label: fig-histograms
#| fig-cap: Histograms of statistical distribution for varibles
#| fig-align: center
#| fig-height: 7
#| fig-width: 6
#| message: false

rating_plot <- ggplot(data=imdb_data, mapping=aes(x=rating))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Rating", y = "Count")+
  theme_bw()

year_plot <- ggplot(data=imdb_data, mapping=aes(x=year))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Year", y = "Count")+
  theme_bw()

length_plot <- ggplot(data=imdb_data, mapping=aes(x=length))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Length", y = "Count")+
  theme_bw()

budget_plot <- ggplot(data=imdb_data, mapping=aes(x=budget))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Budget", y = "Count")+
  theme_bw()

votes_plot <- ggplot(data=imdb_data, mapping=aes(x=votes))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Votes", y = "Count")+
  theme_bw()

log_votes_plot <- ggplot(data=imdb_data, mapping=aes(x=log(votes)))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Votes(log)", y = "Count")+
  theme_bw()

grid.arrange(rating_plot,year_plot,budget_plot,length_plot,votes_plot, log_votes_plot, ncol=2)
```

The variable votes has a large data difference and deviation, so we can log transformation for votes.

```{r}
#Add a new column#
imdb_data <- imdb_data %>%
  mutate(log_votes = log(votes))
```

### Visualise the distributions of categorical variable genre

```{r}
#| label: fig-stacked-barplot
#| fig-cap: Stacked barplot of statistical distribution for ratings by genre.
#| fig-align: center
#| fig-width: 6
#| message: false
ggplot(imdb_data, aes(x = genre, fill = rate)) +
   geom_bar(stat = "count") +
  labs(x = "Genre", y = "Count")+
  theme_bw()+
  theme(legend.position = "bottom") 
```

## The relationship between rating and explanatory variables

Scatterplots to understand the relationship between rating and four variables(year,length,budget,log_votes)

```{r}
#| label: fig-scatterplots-relationship
#| fig-cap: Scatterplots between rating and four explanatory variables. 
#| fig-align: center
#| fig-height: 5
#| message: false
s1 <- ggplot(data=imdb_data, aes(x = year, y = rating, color = rate))+
  geom_point(size=0.5)+
  labs(x = "Year", y = "Rating")+
  theme_bw()

s2 <- ggplot(data=imdb_data, aes(x = length, y = rating, color = rate))+
  geom_point(size=0.5)+
  labs(x = "Length", y = "Rating")+
  theme_bw()

s3 <- ggplot(data=imdb_data, aes(x = budget, y = rating, color = rate))+
  geom_point(size=0.5)+
  labs(x = "Budget", y = "Rating")+
  theme_bw()

s4 <- ggplot(data=imdb_data, aes(x = log_votes , y = rating, color = rate))+
  geom_point(size=0.5)+
  labs(x = "Votes(log)", y = "Rating")+
  theme_bw()

ggarrange(s1,s2,s3,s4,ncol = 2, nrow=2, common.legend = T, legend = "bottom")
```

### Boxplot to understand the relationship between rating and Categorical variable genre

```{r}
#| label: fig-boxplot-ratings
#| fig-cap: Boxplot of ratings by genre.
#| fig-align: center
#| fig-width: 6
#| message: false
ggplot(data =imdb_data, mapping = aes(x = genre, y = rating)) +
  geom_boxplot(fill="skyblue")+
  labs(x = "Genre", y = "Rating")+
  theme_bw()
```

## The relationship response and explanatory variable

### variable1:Length

```{r}
#| label: fig-boxplot-length
#| fig-cap: Boxplot of length by rating.
#| fig-width: 4
#| fig-align: center
#| message: false

#boxplot
ggplot(data = imdb_data, aes(x = rate, y = length,fill=rate) )+
  geom_boxplot() +
  theme_bw()+
  labs(x = "Rating", y = "Length")+
  theme(legend.position = "none") 

length_outliers <- imdb_data %>%
group_by(rate) %>%
  mutate(is_outlier = length > quantile(length, 0.75) + 1.5 * IQR(length) |
           length < quantile(length, 0.25) - 1.5 * IQR(length)) %>%
  filter(is_outlier) %>%
  ungroup() # 97 outliers
```

@fig-boxplot-length shows that the median film length of high rating films is less than that of low rating films. It can Interquartile Range of low rating is smaller than that of high rating, which shows that the data about low rating is more concentrated.

```{r}
#| label: tbl-summary-length
#| tbl-cap: Summary statistics on length by rating.
table=imdb_data %>%
  group_by(rate) %>%
  summarise('Mean' = mean(length),
            'Median' = median(length),
            'St.Dev' = sd(length),
            'Min' = min(length),
            'Max' = max(length),
            'IQR' = quantile(length,0.75)-quantile(length,0.25),
            'Sample_size' = n())
table|>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    rate=html("rate"),
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )
```

The @tbl-summary-length shows that the size of the film with low rating is more than twice as many as that with high rating. The mean length film with high rating(57.95) is lower than that with low rating(95.80).On the whole, highly rated films have a low parity of length phrases. But a low rated films is more stable.

### variable2:Budget

```{r}
#| label: fig-boxplot-budget
#| fig-cap: Boxplot of budget by rating.
#| fig-width: 4
#| fig-align: center
#| message: false
#boxplot
ggplot(data = imdb_data, aes(x = rate, y = budget,fill=rate) )+
  geom_boxplot() +
  labs(x="Rating", y = "Budget")+
  theme_bw()+
  theme(legend.position = "none") 

budget_outliers <- imdb_data %>%
group_by(rate) %>%
  mutate(is_outlier = budget > quantile(budget, 0.75) + 1.5 * IQR(budget) |
           budget < quantile(budget, 0.25) - 1.5 * IQR(budget)) %>%
  filter(is_outlier) %>%
  ungroup() #9 outliers
```

@fig-boxplot-budget shows that the median budget film of high rating films is higher than that of low rating films.

```{r}
#| label: tbl-summary-budget
#| tbl-cap: Summary statistics on budget by rating.
table=imdb_data %>%
  group_by(rate) %>%
  summarise('Mean' = mean(budget),
            'Median' = median(budget),
            'St.Dev' = sd(budget),
            'Min' = min(budget),
            'Max' = max(budget),
            'IQR' = quantile(budget,0.75)-quantile(budget,0.25),
            'Sample_size' = n())

table|>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )
```

The @tbl-summary-budget shows that the mean budget film with high rating(13.09 in \$1000000s) is higher than that with low rating(11.51 in \$1000000s).And the median budget film with high rating(13.00 in \$1000000s) is higher than that with low rating(11.50 in \$1000000s).In general, films with high rating have higher budgets than movies with low rating. ##votes

### variable3:votes(ln)

```{r}
#| label: fig-boxplot-logvotes
#| fig-cap: Boxplot of log_votes by rating.
#| fig-width: 4
#| fig-align: center
#| message: false
ggplot(data = imdb_data, aes(x = rate, y = log_votes,fill=rate) )+
  geom_boxplot() +
  labs(x = "Rating", y = "Votes(log)")+
  theme_bw()+
  theme(legend.position = "none")

log_votes_outliers <- imdb_data %>%
  group_by(rate) %>%
  mutate(is_outlier = log_votes > quantile(log_votes, 0.75) + 1.5 * IQR(log_votes) |
           log_votes < quantile(log_votes, 0.25) - 1.5 * IQR(log_votes)) %>%
  filter(is_outlier) %>%
  ungroup()
```

@fig-boxplot-logvotes shows that the median log_votes film of high rating films is lower than that of low rating films.

```{r}
#| label: tbl-summary-logvotes
#| tbl-cap: Summary statistics of votes(log) by rating.
table=imdb_data %>%
  group_by(rate) %>%
  summarise('Mean' = mean(log_votes),
            'Median' = median(log_votes),
            'St.Dev' = sd(log_votes),
            'Min' = min(log_votes),
            'Max' = max(log_votes),
            'IQR' = quantile(log_votes,0.75)-quantile(log_votes,0.25),
            'Sample_size' = n())

table|>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )
```

The @tbl-summary-logvotes hows that the mean log_votes film with high rating(3.47) is lower than that with low rating(4.03). In general, there were fewer log_votes for films with high ratings.

### variable4:genre

The ratio of ratings above 7 to ratings below 7 and sample sizes for each type

```{r}
library(janitor)

data_1=imdb_data %>%
        group_by(genre)%>%
        count()
colnames(data_1)=c("genre","genre_sum_count")
genre_form=imdb_data %>% 
  tabyl(genre, rate) %>% 
  adorn_percentages() %>% 
  adorn_pct_formatting() %>%
  adorn_ns()%>%
  mutate(genre_sum_count=as.matrix(data_1[2]))
genre_form
```

We can see the size sample about Romance films is only 20,which is too small to fit model.And we also can predict the positive effect of action,Drama on rate score.

```{r}
#| label: fig-dodgedbarplot-genre
#| fig-cap: Dodged barplot of genre by reating.
#| fig-width: 6
#| fig-align: center
#| message: false
ggplot(imdb_data, aes(x = genre, fill = rate)) +
   geom_bar(position = "dodge", stat = "count")+
   labs(x = "Genre", y = "Count")+
  theme_bw()+
  theme(legend.position = "bottom") 
```

@fig-dodgedbarplot-genre shows that the number of low rating films is bigger than the number of high rating films in the genre films about Action,Drama,Romance.Besides,the number of low rating films is smaller than the number of high rating films in the genre films about Animation,Documentary,Short. In genre Comedy, the number of films with high ratings is about the same as the number of films with low scores.

# Formal Data Analysis {#sec-Formal}

## Fitting the Model {#sec-fm}
Baseline category for our binary response high_rating is 0

```{r}
levels(imdb_data$high_rating)
# [1] "0" "1"
```

### Saturated Model {#sec-sat.model}

Include latex equation

```{r}
#| label: tbl-6
#| tbl-cap: Summary for Saturated Model
m0_model <- glm(high_rating~ year + length + budget + log_votes + genre, 
                 data = imdb_data, family = binomial(link="logit"))
summary(m0_model)

m0_coefficients <- summary(m0_model)$coefficients

m0_coefficients_df <- as.data.frame(m0_coefficients) # Create a data frame

m0_coefficients_df$row_names <- rownames(m0_coefficients_df)

m0_coefficients_table <- m0_coefficients_df %>%
  gt(rowname_col = "row_names") %>%
  fmt_number(decimals=3) %>%
  tab_header(
    title = "Summary for Saturated Model"
  )

# Print the table
print(m0_coefficients_table)

```

Baseline category for explanatory variable 'genre' is "Action".

Wald Statistic Z
```{r}
p_values_m0 <- Anova(m0_model, type = 3, 
           test.statistic = "Wald")
print(p_values_m0)
```

log_votes is not statistically significant with a p-value of 0.949925. This suggests that there is insufficient evidence to reject the null hypothesis that the number of votes received by viewers has no effect on the probability of a film being rated as high_rating.

We can look what happens to the residual deviance as we add each term by using anova(m0_model)

**Analysis of Deviance Table**
```{r}
anova(m0_model)
```

Each row in the table represents a term (predictor variable) added to the model.

It can be observed that largest reduction in residual deviance comes when adding 'genre' and the smallest when adding 'year' and 'log_votes'. We could try a model without 'year' and 'log_votes' as the resulting reduction in deviance is smaller than 95th percentile. year":

The change in deviance (3.01) when adding the predictor variable "year" is not statistically significant (p-value \> 0.05), indicating that including "year" does not significantly improve the model fit.The change in deviance (3.26) when adding the predictor variable "log_votes" is not statistically significant (p-value \> 0.05), indicating that including "log_votes" does not significantly improve the model fit.

The same conclusion can be reached if we compare residual deviance and the null deviance. The difference in deviance is 2463.5-1016.8=1446.7 which is much larger than the 95th percentile of a $\chi^2(1936-1926)$

```{r}
2463.5-1016.8 # 1446.7
qchisq(df=10, p=0.95) # 18.30704
```

**Model is a good fit**

The value of the deviance for this model is D = 1016.8. If the model is a good fit, the deviance should approximately follow the $\chi^2(1937-11)$ = $\chi^2(1926)$ distribution. The degrees of freedom are determined as the number of distinct covariate patterns in the data(1937) minus the parameters in the model (11). The 95th percentile of the $\chi^2(1926)$ distribution is 2029.211. Since, 1016.8 < 2029.211, there is no evidence of lack of fit.

```{r}
nrow(distinct(imdb_data, year, length, budget, log_votes, genre)) # 1937

qchisq(df=1926, 0.95) # 2029.211
```


**Assumptions**
```{r}

```


Log-odds & 95% confidence interval for these log-odds
```{r}
m0.coef <- round(coef(m0_model), 3)

m0.logodds <- confint(m0_model) %>%
  kable()
```

Plot of logodds
```{r}
library(sjPlot)
m0_plot_logodds <- plot_model(m0_model, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Rating greater than 7)", show.p = FALSE)
```

Adding estimates of the log-odds to our data set
```{r}
imdb_data_m0 <- imdb_data %>%
  mutate(logodds.m0=predict(m0_model))
```

Odds and 95% Confidence Interval for odds
```{r}
m0.odds <- m0_model %>%
  coef() %>%
  exp() 

m0_log_odds_interval <- confint(m0_model)
m0_odds_interval <- exp(m0_log_odds_interval) %>%
  kable()
```

Plot of odds 
```{r}
m0_plot_odds <-plot_model(m0_model, show.values = TRUE, axis.lim = c(1,1.5),
           title = "Odds", show.p = FALSE)
```

Adding the estimates of the odds to our data set
```{r}
imdb_data_m0 <- imdb_data_m0 %>%
  mutate(odds.m0=exp(logodds.m0))
```

Probabilities add the probabilities to our data, which is done using the fitted() function:
```{r}
imdb_data_m0 <- imdb_data_m0 %>%
  mutate(probs.m1=fitted(m0_model))
```

Plot the Probability being Rating greater than 7
```{r}
plot_model(m0_model, type = "pred", terms = c("length", "budget", "genre"), show.values = TRUE)
```

**Residual Plots**
```{r}
# Calculate residuals
dresiduals_m0 <- resid(m0_model, type = "deviance")
pfitted_m0 <- predict(m0_model, type = "response")

# Create a data frame for plotting
residual_data_m0 <- data.frame(Fitted = pfitted_m0, DevianceResiduals = dresiduals_m0)

# Plot scatter plot
ggplot(residual_data_m0, aes(x = Fitted, y = DevianceResiduals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Fitted Values", y = "Deviance Residuals",
       title = "Scatter Plot of Deviance Residuals vs Fitted Values")
```


### Model 1 {#sec-m1.model}

start model:following equation referring to a logistic regression model
$$ 
\ln\left(\frac{p}{1-p}\right)=\alpha + \beta_1 \cdot \textrm{year}+\beta_2 \cdot \textrm{length}+\beta_3 \cdot \textrm{budget}+\beta_4 \cdot \textrm{log_votes}
+\beta_{\mbox{Animation}} \cdot\mathbb{I}_{\mbox{Animation}}(x)+\\
\beta_{\mbox{Comedy}} \cdot \mathbb{I}_{\mbox{Comedy}}(x)+
\beta_{\mbox{Document}} \cdot \mathbb{I}_{\mbox{Document}}(x)+
\beta_{\mbox{Drama}} \cdot \mathbb{I}_{\mbox{Drama}}(x)+
\beta_{\mbox{Romance}} \cdot \mathbb{I}_{\mbox{Romance}}(x)+
\beta_{\mbox{Short}} \cdot \mathbb{I}_{\mbox{Short}}(x)
$$
$$\mathbb{I}_{\mbox{Genre}}(x)=\left\{
                \begin{array}{ll}
                  1 ~~~ \mbox{if genre of} ~ x \mbox{th observation is Genre},\\
                  0 ~~~ \mbox{Otherwise}.\\
                \end{array}
              \right.\\
              Genre=\{Animation,Comedy,Documentary,Drama,RomanceShort\}$$
```{r}
# Backward stepping stepwise regression using AIC
m1_model <- step(mod_0, direction="both", trace=FALSE)
summary(m1_model)
```

```{r}
m1_model <- glm(high_rating ~ year + length + budget  + genre, 
                 data = imdb_data, family = binomial(link="logit"))
summary(m1_model)

m1_coefficients <- summary(m1_model)$coefficients

m1_coefficients_df <- as.data.frame(m1_coefficients) # Create a data frame

m1_coefficients_df$row_names <- rownames(m1_coefficients_df)

m1_coefficients_table <- m1_coefficients_df %>%
  gt(rowname_col = "row_names") %>%
  fmt_number(decimals=3) %>%
  tab_header(
    title = "Summary for Model 1"
  )

# Print the table
print(m1_coefficients_table)

```

Baseline category for explanatory variable 'genre' is "Action".

```{r}
m0_coefs <- round(coef(m0_model), 2)
```

Log-odds
$$ 
\ln\left(\frac{p}{1-p}\right)=-21+ 0.01 \cdot \textrm{year}-0.06 \cdot \textrm{length}+0.51 \cdot \textrm{budget}+0.00 \cdot \textrm{log_votes}
-0.55 \cdot\mathbb{I}_{\mbox{Animation}}(x)\\
+3.06 \cdot \mathbb{I}_{\mbox{Comedy}}(x)+
5.05 \cdot \mathbb{I}_{\mbox{Document}}(x)
-1.61\cdot \mathbb{I}_{\mbox{Drama}}(x)
-2.16 \cdot \mathbb{I}_{\mbox{Romance}}(x)
+3.55 \cdot \mathbb{I}_{\mbox{Short}}(x)
$$
$$\mathbb{I}_{\mbox{Genre}}(x)=\left\{
                \begin{array}{ll}
                  1 ~~~ \mbox{if genre of} ~ x \mbox{th observation is Genre},\\
                  0 ~~~ \mbox{Otherwise}.\\
                \end{array}
              \right.\\
              Genre=\{Animation,Comedy,Documentary,Drama,RomanceShort\}$$
              
#need analysis the formula

odds
```{r}
exp_m0_coef<-round(exp(m0_coefs) , 2)
exp_m0_coef
```

$$ 
\frac{p}{1-p}=exp\{-21+ 0.01 \cdot \textrm{year}-0.06 \cdot \textrm{length}+0.51 \cdot \textrm{budget}+0.00 \cdot \textrm{log_votes}
-0.55 \cdot\mathbb{I}_{\mbox{Animation}}(x)\\
+3.06 \cdot \mathbb{I}_{\mbox{Comedy}}(x)+
5.05 \cdot \mathbb{I}_{\mbox{Document}}(x)
-1.61\cdot \mathbb{I}_{\mbox{Drama}}(x)
-2.16 \cdot \mathbb{I}_{\mbox{Romance}}(x)
+3.55 \cdot \mathbb{I}_{\mbox{Short}}(x)\}
=.....
Need to supplement
$$
also need analysis

Wald Statistic Z
```{r}
p_values_m1 <- Anova(m1_model, type = 3, 
           test.statistic = "Wald")
print(p_values_m1)
anova(m1_model)
```

All the estimates are statistically significant with a p-value < 0.05. However, looking at residual deviance observe when adding the predictor variable "year" reduction in residual deviance is smallest. 

The same conclusion can be reached if we compare residual deviance and the null deviance. The difference in deviance is 2463.5-1016.8=1446.7 which is much larger than the 95th percentile of a $\chi^2(1936-1927)$

```{r}
2463.5-1016.9 # 1446.6
qchisq(df=9, p=0.95) # 16.91898
```

**Model is a good fit**

The value of the deviance for this model is D = 1016.9. If the model is a good fit, the deviance should approximately follow the $\chi^2(1932-10)$ = $\chi^2(1922)$ distribution. The degrees of freedom are determined as the number of distinct covariate patterns in the data(1932) minus the parameters in the model (10). The 95th percentile of the $\chi^2(1922)$ distribution is 2025.105. Since, 1016.9 < 2025.105, there is no evidence of lack of fit.

```{r}
nrow(distinct(imdb_data, year, length, budget, genre)) # 1932

qchisq(df=1922, 0.95) # 2025.105
```

**Assumptions**

```{r}

```

Log-odds & 95% confidence interval for these log-odds
```{r}
m1.coef <- round(coef(m1_model), 3)

m1.logodds <- confint(m1_model) %>%
  kable()
```

Plot of logodds
```{r}
library(sjPlot)
m1_plot_logodds <- plot_model(m1_model, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Rating greater than 7)", show.p = FALSE)
```

Adding estimates of the log-odds to our data set
```{r}
imdb_data_m1 <- imdb_data %>%
  mutate(logodds.m1=predict(m1_model))
```

Odds and 95% Confidence Interval for odds
```{r}
m1.odds <- m1_model %>%
  coef() %>%
  exp() 

m1_log_odds_interval <- confint(m1_model)
m1_odds_interval <- exp(m1_log_odds_interval) %>%
  kable()
```

Plot of odds 
```{r}
m1_plot_odds <-plot_model(m1_model, show.values = TRUE, axis.lim = c(1,1.5),
           title = "Odds", show.p = FALSE)
```

Adding the estimates of the odds to our data set
```{r}
imdb_data_m1 <- imdb_data_m1 %>%
  mutate(odds.m1=exp(logodds.m1))
```

Probabilities add the probabilities to our data, which is done using the fitted() function:
```{r}
imdb_data_m1 <- imdb_data_m1 %>%
  mutate(probs.m1=fitted(m1_model))
```

Plot the Probability being Rating greater than 7
```{r}
plot_model(m1_model, type = "pred", terms = c("length", "budget", "genre"), show.values = TRUE)
```
It has been find that the probabilities about rating greater than7 decrease by length in terms of the length of the horizontal coordinate. Besides, we also can see that the green line over the blue line, and the blue line over red one. Therefore, it is a conclusion that the probabilities about greater than7 decrease by budget.

**Residual Plots**
```{r}
# Calculate residuals
dresiduals_m1 <- resid(m1_model, type = "deviance")
pfitted_m1 <- predict(m1_model, type = "response")

# Create a data frame for plotting
residual_data_m1 <- data.frame(Fitted = pfitted_m1, DevianceResiduals = dresiduals_m1)

# Plot scatter plot
ggplot(residual_data_m1, aes(x = Fitted, y = DevianceResiduals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Fitted Values", y = "Deviance Residuals",
       title = "Scatter Plot of Deviance Residuals vs Fitted Values")
```

### Model 2 {#sec-m2.model}

Insert Latex Equation

```{r}
# Remove variables with limited contribution to the model: year and log_votes
m2_model <- glm(high_rating ~ length + budget + genre, 
                 data = imdb_data, family = binomial(link="logit"))
summary(m2_model)

m2_coefficients <- summary(m2_model)$coefficients

m2_coefficients_df <- as.data.frame(m2_coefficients) # Create a data frame

m2_coefficients_df$row_names <- rownames(m2_coefficients_df)

m2_coefficients_table <- m2_coefficients_df %>%
  gt(rowname_col = "row_names") %>%
  fmt_number(decimals=3) %>%
  tab_header(
    title = "Summary for Model 2"
  )

# Print the table
print(m2_coefficients_table)

```


Baseline category for explanatory variable 'genre' is "Action".

Wald Statistic Z
```{r}
p_values_m2 <- Anova(m2_model, type = 3, 
           test.statistic = "Wald")
print(p_values_m2)
```

All the estimates are statistically significant  with a p-value < 0.05. 

**Analysis of Deviance Table**
```{r}
anova(m2_model) # model seems okay
```

The same conclusion can be reached if we compare residual deviance and the null deviance. The difference in deviance is 2463.5-1023.2= 1440.3 which is much larger than the 95th percentile of a $\chi^2(1936-1928)$

```{r}
2463.5-1023.2 # 1446.7
qchisq(df=8, p=0.95) # 15.50731
```

**Model is a good fit**

The value of the deviance for this model is D = 1023.2. If the model is a good fit, the deviance should approximately follow the $\chi^2(1825-9)$ = $\chi^2(1816)$ distribution. The degrees of freedom are determined as the number of distinct covariate patterns in the data(1825) minus the parameters in the model (9). The 95th percentile of the $\chi^2(1816)$ distribution is 1916.253. Since, 1023.2 < 1916.253, there is no evidence of lack of fit.

```{r}
nrow(distinct(imdb_data, length, budget, genre)) # 1825

qchisq(df=1816, 0.95) # 1916.253
```

**Assumptions**

```{r}

```

Log-odds & 95% confidence interval for these log-odds
```{r}
m2.coef <- round(coef(m2_model), 3)

m2.logodds <- confint(m2_model) %>%
  kable()
```

Plot of logodds
```{r}
library(sjPlot)
m2_plot_logodds <- plot_model(m2_model, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Rating greater than 7)", show.p = FALSE)
```

Adding estimates of the log-odds to our data set
```{r}
imdb_data_m2 <- imdb_data %>%
  mutate(logodds.m2=predict(m2_model))
```

Odds and 95% Confidence Interval for odds
```{r}
m2.odds <- m2_model %>%
  coef() %>%
  exp() 

m2_log_odds_interval <- confint(m2_model)
m2_odds_interval <- exp(m2_log_odds_interval) %>%
  kable()
```

Plot of odds 
```{r}
m2_plot_odds <-plot_model(m2_model, show.values = TRUE, axis.lim = c(1,1.5),
           title = "Odds", show.p = FALSE)
```

Adding the estimates of the odds to our data set
```{r}
imdb_data_m2 <- imdb_data_m2 %>%
  mutate(odds.m2=exp(logodds.m2))
```

Probabilities add the probabilities to our data, which is done using the fitted() function:
```{r}
imdb_data_m2 <- imdb_data %>%
  mutate(probs.m2=fitted(m2_model))
```

Plot the Probability being Rating greater than 7
```{r}
plot_model(m2_model, type = "pred", terms = c("length", "budget", "genre"), show.values = TRUE)
```

**Residual Plots**
```{r}
# Calculate residuals
dresiduals_m2 <- resid(m2_model, type = "deviance")
pfitted_m2 <- predict(m2_model, type = "response")

# Create a data frame for plotting
residual_data_m2 <- data.frame(Fitted = pfitted_m2, DevianceResiduals = dresiduals_m2)

# Plot scatter plot
ggplot(residual_data_m2, aes(x = Fitted, y = DevianceResiduals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Fitted Values", y = "Deviance Residuals",
       title = "Scatter Plot of Deviance Residuals vs Fitted Values")
```


## Model Checking and Diagnostics (#Sec-mcd)

### Model Selection {#Sec-ms}

```{r}
m0_model <- glm(high_rating ~ year + length + budget + log_votes + genre, 
                           data = imdb_data, family = binomial(link = "logit"))
m1_model <- glm(high_rating ~ year + length + budget + genre, 
                    data = imdb_data, family = binomial(link = "logit"))
m2_model <- glm(high_rating ~ length + budget + genre, 
                    data = imdb_data, family = binomial(link = "logit"))
```

```{r}
# 1. Likelihood Ratio Chi-Squared Statistic Test
lr_test_m1 <- anova(m0_model, m1_model, test = "Chisq") # implies log_votes is not significantly associated with the outcome (p>0.05) therefore m1_model better than m0_model
lr_test_m2 <- anova(m0_model, m2_model, test = "Chisq") # p <0.05 

summary(lr_test_m1)
summary(lr_test_m2)

```

Comparison of m1_model with m0_model shows that the change in Deviance is almost 0 (-0.003943) and Pr(>Chi) = 0.9499, suggesting that the removal of log_votes does not have a significant effect on the fit of the model. Therefore, m1_model maintains a similar fit to m0_model while simplifying the model, indicating that log_votes can be excluded.

Comparing m2_model with m0_model, Deviance increased by 6.3609 and Pr(>Chi) = 0.04157, which is below the 0.05 significance level, indicating that deletion of the year and log_votes from the model, had a significant effect on the fit.

```{r}
# 2. Residuals (e.g., deviance residuals and Pearson_Residual)
# Saturated Model
dres.sat <- resid(m0_model, type="deviance") # Deviance Residuals
pres.sat <- resid(m0_model, type="pearson") #Pearson Residuals
pred.sat <- predict(m0_model, type="response") #Fitted probabilities
d.sat <- data.frame (pred.sat=pred.sat, dres.sat=dres.sat, pres.sat=pres.sat)

g1 <- ggplot(d.sat, aes(x=pred.sat, y=dres.sat))+
  geom_point()

# Model 1
dres.m1 <- resid(m1_model, type="deviance") # Deviance Residuals
pres.m1 <- resid(m1_model, type="pearson") #Pearson Residuals
pred.m1 <- predict(m1_model, type="response") #Fitted probabilities
d.m1 <- data.frame (pred.m1=pred.m1, dres.m1=dres.m1, pres.m1=pres.m1)

g2 <- ggplot(d.m1, aes(x=pred.m1, y=dres.m1))+
  geom_point()

# Model 2
dres.m2 <- resid(m2_model, type="deviance") # Deviance Residuals
pres.m2 <- resid(m2_model, type="pearson") #Pearson Residuals
pred.m2 <- predict(m2_model, type="response") #Fitted probabilities
d.m2 <- data.frame (pred.m2=pred.m2, dres.m2=dres.m2, pres.m2=pres.m2)

g3 <- ggplot(d.m2, aes(x=pred.m2, y=dres.m2))+
  geom_point()

d.sat$Model <- 'm0_model'
d.m1$Model <- 'm1_model'
d.m2$Model <- 'm2_model'

d.m1 <- d.m1 %>% rename(pred.sat=pred.m1, dres.sat=dres.m1, pres.sat=pres.m1)
d.m2 <- d.m2 %>% rename(pred.sat=pred.m2, dres.sat=dres.m2, pres.sat=pres.m2)

all_data <- rbind(d.sat, d.m1, d.m2)

g <- ggplot(all_data, aes(x=pred.sat, y=dres.sat, color=Model)) +
  geom_point() +
  facet_wrap(~Model, scales="free") +
  theme_minimal() +
  labs(x="Fitted Probabilities", y="Deviance Residuals", title="Deviance Residuals Across Models")

g

comparison_table <- all_data %>%
  group_by(Model) %>%
  summarise(Mean_Deviance_Residual = mean(dres.sat),
            Mean_Pearson_Residual = mean(pres.sat),
            Mean_Fitted_Probabilities = mean(pred.sat))

print(comparison_table)

```


A comparison of the Mean Deviance Residual (MDR) shows that the three models do not differ much in their overall effectiveness in fitting the data, with mean values of -0.0470, -0.0469, and -0.0481, respectively. all of the models fit the data well, with no significant difference.

The Mean Pearson Residual (MPR) varies slightly among the three models, with m0_model and m1_model having closer mean values (0.0106 and 0.0107), and m2_model having the lowest mean value (0.00198), suggesting that the m2_model may be a slightly better fit for a given data point than the the other two models. Nevertheless, these differences are very small.

The mean value of Mean Fitted Probabilities (0.332) is exactly the same across all models, suggesting that the average prediction probability of a film receiving a high rating is consistent across models.

In summary, although m2_model shows a slight advantage on Pearson's residuals, model selection should further consider other factors. This includes the analysis of AIC and BIC values, which measure the loss of information and complexity of the model, and the AUC values and ROC curves, which assess the model's ability to classify at different levels of thresholds


```{r}
# 3. ROC curve and AUC #
library(pROC)

# Predictive probability of the model
preds_m0 <- predict(m0_model, type = "response")
preds_m1 <- predict(m1_model, type = "response")
preds_m2 <- predict(m2_model, type = "response")

# Calculate the ROC curve
roc_m0 <- roc(imdb_data$high_rating, preds_m0)
roc_m1 <- roc(imdb_data$high_rating, preds_m1)
roc_m2 <- roc(imdb_data$high_rating, preds_m2)

# Calculate AUC
auc_m0 <- auc(roc_m0)
auc_m1 <- auc(roc_m1)
auc_m2 <- auc(roc_m2)

# Plotting the ROC curve
plot(roc_m0, main="ROC Curves for Three Models", col="#CC0000")
lines(roc_m1, col="#00CC00")
lines(roc_m2, col="#0000CC")

# Add Legend
legend("bottomright", legend=c("m0_model", "m1_model", "m2_model"),
       col=c("#CC0000", "#00CC00", "#0000CC"), lwd=2)

# Print AUC values
cat("AUC for m0_model:", auc_m0, "\n")
cat("AUC for m1_model:", auc_m1, "\n")
cat("AUC for m2_model:", auc_m2, "\n")

```
Comparison of AUC values shows that all models have very high predictive performance, with AUC values above 0.95, implying that the models work well in distinguishing between highly rated and non-highly rated films. m0_model shows the best performance, but the difference with m1_model and m2_model is negligible, suggesting that there is little or no loss in prediction.

Comparison of ROC curves, it can be observed from the figure that the ROC curves of the three models are very close to each other, almost overlapping, and all three curves are very tightly fitted to the upper left corner, indicating that all three models have good predictive ability This suggests that in terms of the balance between the sensitivity (true rate) and the specificity (false positive rate), these models have similar classification ability. This is also confirmed by the AUC values of the models, with m0_model having the highest AUC (0.9516448), but the differences with m1_model (0.9516406) and m2_model (0.9510545) are very slight.

```{r}
# 4. AIC
aic_values <- AIC(m0_model, m1_model, m2_model) # lowest for m1_model

```

Based on the AIC criterion for model selection, m1_model (with log_votes removed) provided the best fit to the data (AIC = 1036.845) while remaining a simple model, compared to m0_model with all variables included (AIC = 1038.841) and m2_model with year and log_votes removed (AIC = 1041.202). Therefore, m1_model is the preferred model, suggesting that the removal of the log_votes variable contributes to the efficiency of the model without significantly affecting its predictive ability.

```{r}

# 5. BIC
bic_values <- BIC(m0_model, m1_model, m2_model) # lowest for m2_model

```

According to the BIC criterion, the m0_model shows the highest BIC value (1100.099), suggesting that this model may not be the most preferred choice. m2_model has a slightly lower BIC (BIC = 1091.322), suggesting that it is a better choice in a statistical perspective. However, considering the significance of the YEAR variable, choosing the m1_model (BIC = 1092.534) that retains the YEAR variable may be a more reasonable decision. This better keeps the validity and explanatory power of the model.

**Goodness of Fit**



# Conclusions {#sec-Conc}

To summarise, we can conclude that m1_model is the best choice of the three models. It provides a model that is both effective and concise by simplifying the model (removing the log_votes variable) without significantly affecting the predictive power of the model. m1_model maintains a high level of accuracy in predicting high ratings, while improving the model's explanatory power by reducing the number of model parameters. Therefore, we recommend using m1_model as a model for predicting whether a film in the IMDb dataset will receive a high rating. In practice, the model is not only effective in making predictions, but its simplicity helps to understand the key factors affecting film ratings.
