---
title: "Group_06"
author: "Analysis of IMDB data set"
number-sections: true
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf:
    geometry: "left=2cm, right=2cm, top=2cm, bottom=2cm"
editor_options: 
  chunk_output_type: console
execute:
  echo: false
  eval: true
  warning: false
  message: false
---

```{r}
#| label: libraries
library(ggplot2)
library(dplyr)
library(tidyverse)
library(gt)
library(patchwork)
library(gridExtra)
library(moderndive)
library(MASS)
library(knitr)
library(GGally)
library(skimr)
library(ggpubr)
```

# Introduction {#sec-Intro}

The study aims to investigate the relationship between various film attributes and IMDB ratings, drawing data from the IMDB film database allocated. The data set comprises of the factors such as film ID, release year, duration, budget, votes, genre, and IMDB rating. The research question focuses on examining the factors that impact IMDB ratings, particularly whether specific film properties contribute to ratings greater than seven. A Generalized Linear Model (GLM) analysis is conducted to derive the relationships between these properties and IMDB ratings.

```{r}
# Import the data sets
imdb_data <- read.csv("dataset06.csv")

```

# Data Wrangling Methods {#sec-DW}

Before we begin the analysis of our data, let's transform the data using various tools. The process below describes the detailed data wrangling techniques that are used to get the desired data set. After having a glimpse of the data set, the 'genre' column is converted to a type factor type.

```{r}
imdb_data$genre <- as.factor(imdb_data$genre) # genre column converted from character type to factor type
```

A check for missing values is conducted and it is found that 103 observations are missing from the column 'length'. Missing values are imputed with the median since median is a robust measure, less impacted by outliers as much as mean. The function *median( )* reveals the median to be 90 minutes. However, it is observed in @tbl-median-length that the median lengths vary across the different genres. With this information, the missing lengths of films are replaced by median length of the respective genre.

```{r}
#| label: tbl-median-length
#| tbl-cap: Median length by genre.
# Check for missing values
missing_values <- colSums(is.na(imdb_data)) # 103 values are missing from the column length

median_length <- median(imdb_data$length, na.rm = TRUE) # median is 90 minutes

median_length_by_genre <- imdb_data %>%
  group_by(genre) %>% 
  summarize(median_length = median(length, na.rm = TRUE))

kable(median_length_by_genre, caption = "Median Length by Genre")

for (i in 1:nrow(median_length_by_genre)) {
  genre <- median_length_by_genre$genre[i]
  median_length <- median_length_by_genre$median_length[i]
  imdb_data$length[imdb_data$genre == genre & is.na(imdb_data$length)] <- median_length
}
```

As per the research question, a new column 'high_rating' containing binary variables coressponding to 'rating' values is created. This column takes a value of 1 for IMDB ratings greater than or equal to seven and 0 for IMDB ratings less than seven. Additionally, another categorical variable 'rate' conveying the same is also added.

```{r}
#new binary column#
imdb_data$high_rating <- ifelse(imdb_data$rating >= 7, 1, 0)
imdb_data$high_rating <- factor(imdb_data$high_rating, levels = c(0, 1))

#Add a categorcial variable as a column
imdb_data$rate<- ifelse(imdb_data$rating >= 7, "Rating greater than 7", "Rating less than 7")
imdb_data$rate <- factor(imdb_data$rate)
```

# Exploratory Data Analysis {#sec-EDA}

## view the data

Check on the size of a data set

```{r}
# check on the size of a data set
dim(imdb_data)
```

Sample size is 1937. And it have 9 variables,7 of which are in the original data.

Let's have a look at the first five rows of the data frame.

```{r}
#| label: tbl-glimpse-dataset
#| tbl-cap: Glimpse of the first five rows in the IMDB data set.
imdb_data |>
  slice_head(n=5) |>
  gt()
```

The variables in @tbl-glimpse-dataset

-   **film.id** : The unique identifier for the film

-   **year** : Year of release of the film in cinemas

-   **length** : Duration (in minutes)

-   **budget** : Budget for the films production (in \$1000000s)

-   **votes** : Number of positive votes received by viewers

-   **genre** : Genre of the film

-   **rating** : IMDB rating from 0 to10

-   **high_rating** : 1 for IMDB ratings greater than or equal to seven and 0 for IMDB ratings less than 7

-   **rate** : 'Rating greater than 7' got high_rating = 1 and 'Rating less than 7' for high_rating = 0

## Summary Statistics {#sec-sum}

Since variables year, length,budget,votes,rating are continuous, we need get their summary contains mean,median,standard deviation,minimum maximum.

```{r}
#| label: tbl-summary-statistics
#| tbl-cap: Summary statistics on the IMDB data by variables.
summary_year <- imdb_data %>%
  summarise('Variables'="year",
            'Mean' = mean(year),
            'Median' = median(year),
            'St.Dev' = sd(year),
            'Min' = min(year),
            'Max' = max(year),
            'IQR' = quantile(year,0.75)-quantile(year,0.25),
            'Sample_size' = n())
summary_length <- imdb_data %>%
  summarise('Variables'="length",
            'Mean' = mean(length),
            'Median' = median(length),
            'St.Dev' = sd(length),
            'Min' = min(length),
            'Max' = max(length),
            'IQR' = quantile(length,0.75)-quantile(length,0.25),
            'Sample_size' = n())
summary_budget <- imdb_data %>%
  summarise('Variables'="budget",
            'Mean' = mean(budget),
            'Median' = median(budget),
            'St.Dev' = sd(budget),
            'Min' = min(budget),
            'Max' = max(budget),
            'IQR' = quantile(budget,0.75)-quantile(budget,0.25),
            'Sample_size' = n())
summary_votes <- imdb_data %>%
  summarise('Variables'="votes",
            'Mean' = mean(votes),
            'Median' = median(votes),
            'St.Dev' = sd(votes),
            'Min' = min(votes),
            'Max' = max(votes),
            'IQR' = quantile(votes,0.75)-quantile(votes,0.25),
            'Sample_size' = n())
summary_rating <- imdb_data %>%
  summarise('Variables'="rating",
            'Mean' = mean(rating),
            'Median' = median(rating),
            'St.Dev' = sd(rating),
            'Min' = min(rating),
            'Max' = max(rating),
            'IQR' = quantile(rating,0.75)-quantile(rating,0.25),
            'Sample_size' = n())

combined_summary <- bind_rows(summary_year, summary_length, summary_budget, summary_votes, summary_rating)
combined_summary |>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Variables=html("Variables"),
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  ) 
```

The @tbl-summary-statistics shows that the summary for the columns year, length, budget and votes.

• The number of films in sample is 1937.

• For the variable year, the years of the films ranged from 1896 to 2005.

• For the variable length, the films runs from 1 minute to 316 minutes.The average length of a movie is 83.22 minutes.

• For variable budget, the budget of films is from 3.2 (\$1000000s) to 21.2 (\$1000000s).The median budget of a movie is 12(\$1000000s).

• For variable votes, the votes of films is from 5 to 103,854.The range of variation is very large, and the IQR is relatively large. The data is not stable.

## Correlation {#sec-cor}

Check correlations (as scatterplots), distribution and print correlation coefficient.

```{r}
#| label: fig-scatterplot-matrix
#| fig-cap: Scatterplot matrix between rating and explanatory variables.
#| fig-align: center
#| fig-width: 7
#| fig-height: 6
#| message: false
scatterplot_matrix <- ggpairs(imdb_data[, c("rating","year", "budget",  "length", "votes")], 
                              title="Scatterplot matrix")
scatterplot_matrix
```

@fig-scatterplot-matrix shows rating and budget show a significant linear positive correlation. And rating is significant linear negative correlation with length. Between rating and year,votes have weak correlation.

## Visualization {#sec-viz}

### Histograms for continuous variable(rating,year,budget,length,votes)

Histograms to understand the data structures of different variables

```{r}
#| label: fig-histograms
#| fig-cap: Histograms of statistical distribution for varibles
#| fig-align: center
#| fig-height: 7
#| fig-width: 6
#| message: false

rating_plot <- ggplot(data=imdb_data, mapping=aes(x=rating))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Rating", y = "Count")+
  theme_bw()

year_plot <- ggplot(data=imdb_data, mapping=aes(x=year))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Year", y = "Count")+
  theme_bw()

length_plot <- ggplot(data=imdb_data, mapping=aes(x=length))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Length", y = "Count")+
  theme_bw()

budget_plot <- ggplot(data=imdb_data, mapping=aes(x=budget))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Budget", y = "Count")+
  theme_bw()

votes_plot <- ggplot(data=imdb_data, mapping=aes(x=votes))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Votes", y = "Count")+
  theme_bw()

log_votes_plot <- ggplot(data=imdb_data, mapping=aes(x=log(votes)))+
  geom_histogram(color = "black",fill="skyblue")+
  labs(x = "Votes(log)", y = "Count")+
  theme_bw()

grid.arrange(rating_plot,year_plot,budget_plot,length_plot,votes_plot, log_votes_plot, ncol=2)
```

The variable votes has a large data difference and deviation, so we can log transformation for votes.

```{r}
#Add a new column#
imdb_data <- imdb_data %>%
  mutate(log_votes = log(votes))
```

### Visualise the distributions of categorical variable genre

```{r}
#| label: fig-stacked-barplot
#| fig-cap: Stacked barplot of statistical distribution for ratings by genre.
#| fig-align: center
#| fig-width: 6
#| message: false
ggplot(imdb_data, aes(x = genre, fill = rate)) +
   geom_bar(stat = "count") +
  labs(x = "Genre", y = "Count")+
  theme_bw()+
  theme(legend.position = "bottom") 
```

## The relationship between rating and explanatory variables

Scatterplots to understand the relationship between rating and four variables(year,length,budget,log_votes)

```{r}
#| label: fig-scatterplots-relationship
#| fig-cap: Scatterplots between rating and four explanatory variables. 
#| fig-align: center
#| fig-height: 5
#| message: false
s1 <- ggplot(data=imdb_data, aes(x = year, y = rating, color = rate))+
  geom_point(size=0.5)+
  labs(x = "Year", y = "Rating")+
  theme_bw()

s2 <- ggplot(data=imdb_data, aes(x = length, y = rating, color = rate))+
  geom_point(size=0.5)+
  labs(x = "Length", y = "Rating")+
  theme_bw()

s3 <- ggplot(data=imdb_data, aes(x = budget, y = rating, color = rate))+
  geom_point(size=0.5)+
  labs(x = "Budget", y = "Rating")+
  theme_bw()

s4 <- ggplot(data=imdb_data, aes(x = log_votes , y = rating, color = rate))+
  geom_point(size=0.5)+
  labs(x = "Votes(log)", y = "Rating")+
  theme_bw()

ggarrange(s1,s2,s3,s4,ncol = 2, nrow=2, common.legend = T, legend = "bottom")
```

### Boxplot to understand the relationship between rating and Categorical variable genre

```{r}
#| label: fig-boxplot-ratings
#| fig-cap: Boxplot of ratings by genre.
#| fig-align: center
#| fig-width: 6
#| message: false
ggplot(data =imdb_data, mapping = aes(x = genre, y = rating)) +
  geom_boxplot(fill="skyblue")+
  labs(x = "Genre", y = "Rating")+
  theme_bw()
```

## The relationship response and explanatory variable

### variable1:Length

```{r}
#| label: fig-boxplot-length
#| fig-cap: Boxplot of length by rating.
#| fig-width: 4
#| fig-align: center
#| message: false

#boxplot
ggplot(data = imdb_data, aes(x = rate, y = length,fill=rate) )+
  geom_boxplot() +
  theme_bw()+
  labs(x = "Rating", y = "Length")+
  theme(legend.position = "none") 

length_outliers <- imdb_data %>%
group_by(rate) %>%
  mutate(is_outlier = length > quantile(length, 0.75) + 1.5 * IQR(length) |
           length < quantile(length, 0.25) - 1.5 * IQR(length)) %>%
  filter(is_outlier) %>%
  ungroup() # 97 outliers
```

@fig-boxplot-length shows that the median film length of high rating films is less than that of low rating films. It can Interquartile Range of low rating is smaller than that of high rating, which shows that the data about low rating is more concentrated.

```{r}
#| label: tbl-summary-length
#| tbl-cap: Summary statistics on length by rating.
table=imdb_data %>%
  group_by(rate) %>%
  summarise('Mean' = mean(length),
            'Median' = median(length),
            'St.Dev' = sd(length),
            'Min' = min(length),
            'Max' = max(length),
            'IQR' = quantile(length,0.75)-quantile(length,0.25),
            'Sample_size' = n())
table|>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    rate=html("rate"),
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )
```

The @tbl-summary-length shows that the size of the film with low rating is more than twice as many as that with high rating. The mean length film with high rating(57.95) is lower than that with low rating(95.80).On the whole, highly rated films have a low parity of length phrases. But a low rated films is more stable.

### variable2:Budget

```{r}
#| label: fig-boxplot-budget
#| fig-cap: Boxplot of budget by rating.
#| fig-width: 4
#| fig-align: center
#| message: false
#boxplot
ggplot(data = imdb_data, aes(x = rate, y = budget,fill=rate) )+
  geom_boxplot() +
  labs(x="Rating", y = "Budget")+
  theme_bw()+
  theme(legend.position = "none") 

budget_outliers <- imdb_data %>%
group_by(rate) %>%
  mutate(is_outlier = budget > quantile(budget, 0.75) + 1.5 * IQR(budget) |
           budget < quantile(budget, 0.25) - 1.5 * IQR(budget)) %>%
  filter(is_outlier) %>%
  ungroup() #9 outliers
```

@fig-boxplot-budget shows that the median budget film of high rating films is higher than that of low rating films.

```{r}
#| label: tbl-summary-budget
#| tbl-cap: Summary statistics on budget by rating.
table=imdb_data %>%
  group_by(rate) %>%
  summarise('Mean' = mean(budget),
            'Median' = median(budget),
            'St.Dev' = sd(budget),
            'Min' = min(budget),
            'Max' = max(budget),
            'IQR' = quantile(budget,0.75)-quantile(budget,0.25),
            'Sample_size' = n())

table|>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )
```

The @tbl-summary-budget shows that the mean budget film with high rating(13.09 in \$1000000s) is higher than that with low rating(11.51 in \$1000000s).And the median budget film with high rating(13.00 in \$1000000s) is higher than that with low rating(11.50 in \$1000000s).In general, films with high rating have higher budgets than movies with low rating. ##votes

### variable3:votes(ln)

```{r}
#| label: fig-boxplot-logvotes
#| fig-cap: Boxplot of log_votes by rating.
#| fig-width: 4
#| fig-align: center
#| message: false
ggplot(data = imdb_data, aes(x = rate, y = log_votes,fill=rate) )+
  geom_boxplot() +
  labs(x = "Rating", y = "Votes(log)")+
  theme_bw()+
  theme(legend.position = "none")

log_votes_outliers <- imdb_data %>%
  group_by(rate) %>%
  mutate(is_outlier = log_votes > quantile(log_votes, 0.75) + 1.5 * IQR(log_votes) |
           log_votes < quantile(log_votes, 0.25) - 1.5 * IQR(log_votes)) %>%
  filter(is_outlier) %>%
  ungroup()
```

@fig-boxplot-logvotes shows that the median log_votes film of high rating films is lower than that of low rating films.

```{r}
#| label: tbl-summary-logvotes
#| tbl-cap: Summary statistics of votes(log) by rating.
table=imdb_data %>%
  group_by(rate) %>%
  summarise('Mean' = mean(log_votes),
            'Median' = median(log_votes),
            'St.Dev' = sd(log_votes),
            'Min' = min(log_votes),
            'Max' = max(log_votes),
            'IQR' = quantile(log_votes,0.75)-quantile(log_votes,0.25),
            'Sample_size' = n())

table|>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )
```

The @tbl-summary-logvotes hows that the mean log_votes film with high rating(3.47) is lower than that with low rating(4.03). In general, there were fewer log_votes for films with high ratings.

### variable4:genre

The ratio of ratings above 7 to ratings below 7 and sample sizes for each type

```{r}
library(janitor)

data_1=imdb_data %>%
        group_by(genre)%>%
        count()
colnames(data_1)=c("genre","genre_sum_count")
genre_form=imdb_data %>% 
  tabyl(genre, rate) %>% 
  adorn_percentages() %>% 
  adorn_pct_formatting() %>%
  adorn_ns()%>%
  mutate(genre_sum_count=as.matrix(data_1[2]))
genre_form
```

We can see the size sample about Romance films is only 20,which is too small to fit model.And we also can predict the positive effect of action,Drama on rate score.

```{r}
#| label: fig-dodgedbarplot-genre
#| fig-cap: Dodged barplot of genre by reating.
#| fig-width: 6
#| fig-align: center
#| message: false
ggplot(imdb_data, aes(x = genre, fill = rate)) +
   geom_bar(position = "dodge", stat = "count")+
   labs(x = "Genre", y = "Count")+
  theme_bw()+
  theme(legend.position = "bottom") 
```

@fig-dodgedbarplot-genre shows that the number of low rating films is bigger than the number of high rating films in the genre films about Action,Drama,Romance.Besides,the number of low rating films is smaller than the number of high rating films in the genre films about Animation,Documentary,Short. In genre Comedy, the number of films with high ratings is about the same as the number of films with low scores.

# Formal Data Analysis {#sec-Formal}

## Fitting the Model {#sec-fm}

Baseline category for our binary response high_rating is 0

```{r}
levels(imdb_data$high_rating)
# [1] "0" "1"
```

### Saturated Model {#sec-sat.model}

Include latex equation

```{r}
#| label: tbl-6
#| tbl-cap: Summary for Saturated Model
m0_model <- glm(high_rating~ year + length + budget + log_votes + genre, 
                 data = imdb_data, family = binomial(link="logit"))
summary(m0_model)

m0_coefficients <- summary(m0_model)$coefficients

m0_coefficients_df <- as.data.frame(m0_coefficients) # Create a data frame

m0_coefficients_df$row_names <- rownames(m0_coefficients_df)

m0_coefficients_table <- m0_coefficients_df %>%
  gt(rowname_col = "row_names") %>%
  fmt_number(decimals=3) %>%
  tab_header(
    title = "Summary for Saturated Model"
  )

# Print the table
print(m0_coefficients_table)

```

Baseline category for explanatory variable 'genre' is "Action".

**Variable Selection** log_votes has a p-value of 0.7597. This suggests that there this variable should be included in the model.

**Hypothesis Testing** Since log-votes has p-value \> 0.05, it is not statistically significant and does not contribute in explaining the variation in the response variable.

**Analysis of Deviance Table**

```{r}
d0 <- anova(m0_model) %>%
  kable()
```

Each row in the table represents a term (predictor variable) added to the model. It can be observed that largest reduction in residual deviance comes when adding 'genre' and the smallest when adding 'year' and 'log_votes'. A model without 'year' and 'log_votes' could be tried.

**Model is a good fit** The value of the deviance for this model is D = 1018. If the model is a good fit, the deviance should approximately follow the $\chi^2(1936-11)$ = $\chi^2(1926)$ distribution. The degrees of freedom are determined as the number of distinct covariate patterns in the data(1936) minus the parameters in the model (11). The 95th percentile of the $\chi^2(1926)$ distribution is 2029.211. Since, 1018 \< 2029.211, there is no evidence of lack of fit.

```{r}
nrow(distinct(imdb_data, year, length, budget, log_votes, genre)) # 1936
qchisq(df=1926, 0.95) # 2029.211
```

**Assumptions**

Residuals should be normally distributed Independence of observations Linearity of continuous explanatory variables and the log-odds outcome No multicollinearity - explanatory variables should not be highly correlated with each other

```{r}
autoplot(m0_model)
```

### Model 1 {#sec-m1.model}

start model:following equation referring to a logistic regression model $$ 
\ln\left(\frac{p}{1-p}\right)=\alpha + \beta_1 \cdot \textrm{year}+\beta_2 \cdot \textrm{length}+\beta_3 \cdot \textrm{budget}+\beta_4 \cdot \textrm{log_votes}
+\beta_{\mbox{Animation}} \cdot\mathbb{I}_{\mbox{Animation}}(x)+\\
\beta_{\mbox{Comedy}} \cdot \mathbb{I}_{\mbox{Comedy}}(x)+
\beta_{\mbox{Document}} \cdot \mathbb{I}_{\mbox{Document}}(x)+
\beta_{\mbox{Drama}} \cdot \mathbb{I}_{\mbox{Drama}}(x)+
\beta_{\mbox{Romance}} \cdot \mathbb{I}_{\mbox{Romance}}(x)+
\beta_{\mbox{Short}} \cdot \mathbb{I}_{\mbox{Short}}(x)
$$ $$\mathbb{I}_{\mbox{Genre}}(x)=\left\{
                \begin{array}{ll}
                  1 ~~~ \mbox{if genre of} ~ x \mbox{th observation is Genre},\\
                  0 ~~~ \mbox{Otherwise}.\\
                \end{array}
              \right.\\
              Genre=\{Animation,Comedy,Documentary,Drama,RomanceShort\}$$

```{r}
m1_model <- glm(high_rating ~ year + length + budget  + genre, 
                 data = imdb_data, family = binomial(link="logit"))
summary(m1_model)

m1_coefficients <- summary(m1_model)$coefficients

m1_coefficients_df <- as.data.frame(m1_coefficients) # Create a data frame

m1_coefficients_df$row_names <- rownames(m1_coefficients_df)

m1_coefficients_table <- m1_coefficients_df %>%
  gt(rowname_col = "row_names") %>%
  fmt_number(decimals=3) %>%
  tab_header(
    title = "Summary for Model 1"
  )

# Print the table
print(m1_coefficients_table)

```

**Variable Selection** All the estimates are statistically significant with a p-value \< 0.05. However, looking at residual deviance in table observe when adding the predictor variable "year" reduction in residual deviance is smallest.

**Hypothesis Testing** Since p-values \> 0.05 for all the parameters, the predictors are statistically significant and contributes to explaining the variation in the response variable.

**Model is a good fit** The value of the deviance for this model is D = 1018.1. If the model is a good fit, the deviance should approximately follow the $\chi^2(1927-10)$ = $\chi^2(1917)$ distribution. The degrees of freedom are determined as the number of distinct covariate patterns in the data(1927) minus the parameters in the model (10). The 95th percentile of the $\chi^2(1926)$ distribution is 2019.972. Since, 1018.1 \< 2019.972, there is no evidence of lack of fit.

```{r}
nrow(distinct(imdb_data, year, length, budget, genre)) # 1927

qchisq(df=1917, 0.95) # 2019.972
```

**Assumptions**

```{r}
autoplot(m1_model)
```

### Model 2 {#sec-m2.model}

Insert Latex Equation

```{r}
# Remove variables with limited contribution to the model: year and log_votes
m2_model <- glm(high_rating ~ length + budget + genre, 
                 data = imdb_data, family = binomial(link="logit"))
summary(m2_model)

m2_coefficients <- summary(m2_model)$coefficients

m2_coefficients_df <- as.data.frame(m2_coefficients) # Create a data frame

m2_coefficients_df$row_names <- rownames(m2_coefficients_df)

m2_coefficients_table <- m2_coefficients_df %>%
  gt(rowname_col = "row_names") %>%
  fmt_number(decimals=3) %>%
  tab_header(
    title = "Summary for Model 2"
  )

# Print the table
print(m2_coefficients_table)

```

**Variable Selection** All the estimates are statistically significant with a p-value \< 0.05.

**Hypothesis Testing** Since p-values \> 0.05 for all the parameters, the predictors are statistically significant and contributes to explaining the variation in the response variable.

**Model is a good fit** The value of the deviance for this model is D = 1025.2. If the model is a good fit, the deviance should approximately follow the $\chi^2(1928-9)$ = $\chi^2(1919)$ distribution. The degrees of freedom are determined as the number of distinct covariate patterns in the data(1927) minus the parameters in the model (09). The 95th percentile of the $\chi^2(1919)$ distribution is 2022.026. Since, 1025.2 \< 2022.026, there is no evidence of lack of fit.

```{r}
nrow(distinct(imdb_data, year, length, budget, genre)) # 1927
qchisq(df=1919, 0.95) # 2025.105
```

**Assumptions**

```{r}
autoplot(m2_model)
```

Log-odds & 95% confidence interval for these log-odds

```{r}
m2.coef <- round(coef(m2_model), 3)
m2.logodds <- confint(m2_model) %>%
  kable()
```

Plot of logodds

```{r}
library(sjPlot)
m2_plot_logodds <- plot_model(m2_model, show.values = TRUE, transform = NULL,
           title = "Log-Odds (Rating greater than 7)", show.p = FALSE)
```

Adding estimates of the log-odds to our data set

```{r}
imdb_data_m2 <- imdb_data %>%
  mutate(logodds.m2=predict(m2_model))
```

Odds and 95% Confidence Interval for odds

```{r}
m2.odds <- m2_model %>%
  coef() %>%
  exp() 

m2_log_odds_interval <- confint(m2_model)
m2_odds_interval <- exp(m2_log_odds_interval) %>%
  kable()
```

Plot of odds

```{r}
m2_plot_odds <-plot_model(m2_model, show.values = TRUE, axis.lim = c(1,1.5),
           title = "Odds", show.p = FALSE)
```

Adding the estimates of the odds to our data set

```{r}
imdb_data_m2 <- imdb_data_m2 %>%
  mutate(odds.m2=exp(logodds.m2))
```

Probabilities add the probabilities to our data, which is done using the fitted() function:

```{r}
imdb_data_m2 <- imdb_data %>%
  mutate(probs.m2=fitted(m2_model))
```

Plot the Probability being Rating greater than 7

```{r}
plot_model(m2_model, type = "pred", terms = c("length", "budget", "genre"), show.values = TRUE)
```

## Model Checking and Diagnostics (#Sec-mcd)

### Model Selection {#Sec-ms}

1.  Likelihood Ratio Chi-Squared Statistic Test

```{r}
# 1. Likelihood Ratio Chi-Squared Statistic Test
lr_test_m1 <- anova(m0_model, m1_model, test = "Chisq") # implies log_votes is not significantly associated with the outcome (p>0.05) therefore m1_model better than m0_model
lr_test_m2 <- anova(m0_model, m2_model, test = "Chisq") # p <0.05 
```

2.  Residuals

```{r}
# 2. Residuals (e.g., deviance residuals and Pearson_Residual)
# Saturated Model
dres.m0 <- resid(m0_model, type="deviance") # Deviance Residuals
pres.m0 <- resid(m0_model, type="pearson") #Pearson Residuals
pred.m0 <- predict(m0_model, type="response") #Fitted probabilities
d.m0 <- data.frame (pred.m0=pred.m0, dres.m0=dres.m0, pres.m0=pres.m0)

g1 <- ggplot(d.m0, aes(x=pred.m0, y=dres.m0))+
  geom_point(color="red") +
  labs(x="Fitted Probabilities", y="Deviance Residuals", title="mo_model")+
  theme_minimal()

# Model 1
dres.m1 <- resid(m1_model, type="deviance") # Deviance Residuals
pres.m1 <- resid(m1_model, type="pearson") #Pearson Residuals
pred.m1 <- predict(m1_model, type="response") #Fitted probabilities
d.m1 <- data.frame (pred.m1=pred.m1, dres.m1=dres.m1, pres.m1=pres.m1)

g2 <- ggplot(d.m1, aes(x=pred.m1, y=dres.m1))+
  geom_point(color="green") +
  labs(x="Fitted Probabilities", y="Deviance Residuals", title="m1_model")+
  theme_minimal()

# Model 2
dres.m2 <- resid(m2_model, type="deviance") # Deviance Residuals
pres.m2 <- resid(m2_model, type="pearson") #Pearson Residuals
pred.m2 <- predict(m2_model, type="response") #Fitted probabilities
d.m2 <- data.frame (pred.m2=pred.m2, dres.m2=dres.m2, pres.m2=pres.m2)

g3 <- ggplot(d.m2, aes(x=pred.m2, y=dres.m2))+
  geom_point(color="blue")+
  labs(x="Fitted Probabilities", y="Deviance Residuals", title="m2_model")+
  theme_minimal()

grid.arrange(g1, g2, g3, ncol=3)


d.m0$Model <- 'm0_model'
d.m1$Model <- 'm1_model'
d.m2$Model <- 'm2_model'
d.m1 <- d.m1 %>% rename(pred.m0=pred.m1, dres.m0=dres.m1, pres.m0=pres.m1)
d.m2 <- d.m2 %>% rename(pred.m0=pred.m2, dres.m0=dres.m2, pres.m0=pres.m2)
all_data <- rbind(d.m0, d.m1, d.m2)

model_comparison_table <- all_data %>%
  group_by(Model) %>%
  summarise(Mean_Deviance_Residual = mean(dres.m0),
            Mean_Pearson_Residual = mean(pres.m0),
            Mean_Fitted_Probabilities = mean(pred.m0)) %>%
  gt() %>%
  tab_header(
    title = "Model Comparison Table")
print(model_comparison_table)
```

A comparison of the [Mean Deviance Residual (MDR)]{.underline} all of the models fit the data well, with no significant difference.

[Mean Pearson Residual (MPR)]{.underline} varies slightly among the three models, with m0_model and m1_model having closer mean values and m2_model having the lowest mean value (-0.00991), suggesting that the m2_model may be a slightly better fit than the the other two models.

The mean value of [Mean Fitted Probabilities]{.underline} (0.332) is same across all models, suggesting that the average prediction probability of a film receiving 'Rating greater than 7' is consistent across models.

3.  ROC curve and AUC

```{r}
# 3. ROC curve and AUC #
# Predictive probability of the model
preds_m0 <- predict(m0_model, type = "response")
preds_m1 <- predict(m1_model, type = "response")
preds_m2 <- predict(m2_model, type = "response")

# Calculate the ROC curve
roc_m0 <- roc(imdb_data$high_rating, preds_m0)
roc_m1 <- roc(imdb_data$high_rating, preds_m1)
roc_m2 <- roc(imdb_data$high_rating, preds_m2)

# Calculate AUC
auc_m0 <- auc(roc_m0)
auc_m1 <- auc(roc_m1)
auc_m2 <- auc(roc_m2)

par(mfrow = c(1, 1))

# Plotting the ROC curve
plot(roc_m0, main="ROC Curves for Three Models", col="red")
lines(roc_m1, col="green")
lines(roc_m2, col="blue")
legend("bottomright", legend=c("m0_model", "m1_model", "m2_model"),
       col=c("red", "green", "blue"), lwd=2)

# Print AUC values
cat("AUC for m0_model:", auc_m0, "\n")
cat("AUC for m1_model:", auc_m1, "\n")
cat("AUC for m2_model:", auc_m2, "\n")

```

[Comparison of AUC values]{.underline} shows that all models have very high predictive performance, with AUC values most 0.95, implying that the models work well in distinguishing between 'Rating greater than 7' and 'Rating less than 7' films. m0_model shows the best performance, but the difference with m1_model and m2_model is negligible, suggesting that there is little or no loss in prediction.

[Comparison of ROC curves]{.underline}, it can be observed from the figure that the ROC curves of the three models are very close to each other, almost overlapping, and all three curves are very tightly fitted to the upper left corner, indicating that all three models have good predictive ability This suggests that in terms of the balance between the sensitivity (true rate) and the specificity (false positive rate), these models have similar classification ability. This is also confirmed by the AUC values of the models, with m0_model having the highest AUC (0.9519078 ), but the differences with m1_model (0.9518664) and m2_model (0.9512197 ) are very slight.

4.  AIC & BIC

```{r}
# 4. AIC
aic_values <- AIC(m0_model, m1_model, m2_model) # lowest for m1_model 
aic_data <- data.frame(Model = c("m0_model", "m1_model", "m2_model"),                       aic_values) 
table_aic <- aic_data %>%   
  gt() %>%   
  tab_header(title = "AIC Values for Models") 
print(table_aic)
```

Based on the AIC criterion for model selection, m1_model (with log_votes removed) provided the best fit to the data (AIC = 1038.067) compared to m0_model with all variables included (AIC = 1039.973). Therefore, m1_model is the preferred model.

```{r}
# 5. BIC
bic_values <- BIC(m0_model, m1_model, m2_model) # lowest for m2_model
bic_data <- data.frame(Model = c("m0_model", "m1_model", "m2_model"),
                       bic_values)
table_bic <- bic_data %>%
  gt() %>%
  tab_header(
    title = "BIC Values for Models"
  )
print(table_bic)
```

According to the BIC criterion, the m0_model shows the highest BIC value (1101.231), suggesting that this model may not be the most preferred choice. m1_model has a lowest BIC (BIC = 1093.290), suggesting that it is a better choice in a statistical perspective.

# Conclusions {#sec-Conc}
